{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec71c59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install vk_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de729b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: vk in c:\\programdata\\anaconda3\\lib\\site-packages (3.0)\n",
      "Requirement already satisfied: requests~=2.24 in c:\\programdata\\anaconda3\\lib\\site-packages (from vk) (2.26.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests~=2.24->vk) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests~=2.24->vk) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests~=2.24->vk) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests~=2.24->vk) (1.26.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -eaborn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ackaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -eaborn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ackaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -eaborn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ackaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -eaborn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ackaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -eaborn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ackaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -eaborn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ackaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install vk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eeccf3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transliterate in c:\\programdata\\anaconda3\\lib\\site-packages (1.10.2)\n",
      "Requirement already satisfied: six>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from transliterate) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -eaborn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ackaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -eaborn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ackaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -eaborn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ackaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -eaborn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ackaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -eaborn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ackaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -eaborn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ackaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install transliterate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c5e35d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wordcloud in c:\\programdata\\anaconda3\\lib\\site-packages (1.8.2.2)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from wordcloud) (1.20.3)\n",
      "Note: you may need to restart the kernel to use updated packages.Requirement already satisfied: matplotlib in c:\\programdata\\anaconda3\\lib\\site-packages (from wordcloud) (3.4.3)\n",
      "Requirement already satisfied: pillow in c:\\programdata\\anaconda3\\lib\\site-packages (from wordcloud) (8.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.8.2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -eaborn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ackaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -eaborn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ackaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (0.10.0)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib->wordcloud) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -eaborn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ackaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -eaborn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ackaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -eaborn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ackaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -eaborn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ackaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7487886a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\programdata\\anaconda3\\lib\\site-packages (4.27.4)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (21.0)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (3.3.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (2021.8.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (1.20.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (2.26.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Note: you may need to restart the kernel to use updated packages.Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -eaborn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ackaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -eaborn (c:\\programdata\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ackaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -eaborn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ackaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -eaborn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ackaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -eaborn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ackaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -eaborn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ackaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c1cc6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\programdata\\anaconda3\\lib\\site-packages (2.0.0)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.3.1)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (2.6.3)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (2.11.3)\n",
      "Requirement already satisfied: sympy in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (1.9)\n",
      "Requirement already satisfied: typing-extensions in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.10.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch) (1.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy->torch) (1.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -eaborn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ackaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -eaborn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ackaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -eaborn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ackaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -eaborn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ackaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -eaborn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ackaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -eaborn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ackaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2986b852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: umap in c:\\programdata\\anaconda3\\lib\\site-packages (0.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -eaborn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ackaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -eaborn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ackaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -eaborn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ackaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -eaborn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ackaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -eaborn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ackaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -eaborn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ackaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c1ed5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hdbscan in c:\\programdata\\anaconda3\\lib\\site-packages (0.8.29)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\programdata\\anaconda3\\lib\\site-packages (from hdbscan) (1.20.3)\n",
      "Requirement already satisfied: scikit-learn>=0.20 in c:\\programdata\\anaconda3\\lib\\site-packages (from hdbscan) (0.24.2)\n",
      "Requirement already satisfied: joblib>=1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from hdbscan) (1.1.0)\n",
      "Requirement already satisfied: cython>=0.27 in c:\\programdata\\anaconda3\\lib\\site-packages (from hdbscan) (0.29.24)\n",
      "Requirement already satisfied: scipy>=1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from hdbscan) (1.7.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20->hdbscan) (2.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -eaborn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ackaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -eaborn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ackaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -eaborn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ackaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -eaborn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ackaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -eaborn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ackaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -eaborn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ackaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install hdbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82eff2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nb_black in c:\\programdata\\anaconda3\\lib\\site-packages (1.0.7)\n",
      "Requirement already satisfied: black>='19.3' in c:\\programdata\\anaconda3\\lib\\site-packages (from nb_black) (19.10b0)\n",
      "Requirement already satisfied: ipython in c:\\programdata\\anaconda3\\lib\\site-packages (from nb_black) (7.29.0)Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: regex in c:\\programdata\\anaconda3\\lib\\site-packages (from black>='19.3'->nb_black) (2021.8.3)\n",
      "Requirement already satisfied: attrs>=18.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from black>='19.3'->nb_black) (21.2.0)\n",
      "Requirement already satisfied: typed-ast>=1.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from black>='19.3'->nb_black) (1.4.3)\n",
      "Requirement already satisfied: toml>=0.9.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from black>='19.3'->nb_black) (0.10.2)\n",
      "Requirement already satisfied: appdirs in c:\\programdata\\anaconda3\\lib\\site-packages (from black>='19.3'->nb_black) (1.4.4)\n",
      "Requirement already satisfied: pathspec<1,>=0.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from black>='19.3'->nb_black) (0.7.0)\n",
      "\n",
      "Requirement already satisfied: click>=6.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from black>='19.3'->nb_black) (8.0.3)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from click>=6.5->black>='19.3'->nb_black) (0.4.4)\n",
      "Requirement already satisfied: decorator in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython->nb_black) (5.1.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython->nb_black) (3.0.20)\n",
      "Requirement already satisfied: setuptools>=18.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython->nb_black) (58.0.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -eaborn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ackaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -eaborn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ackaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -eaborn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ackaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -eaborn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ackaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -eaborn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ackaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -eaborn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ckaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ackaging (c:\\programdata\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: traitlets>=4.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython->nb_black) (5.1.0)\n",
      "Requirement already satisfied: pickleshare in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython->nb_black) (0.7.5)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython->nb_black) (0.18.0)\n",
      "Requirement already satisfied: backcall in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython->nb_black) (0.2.0)\n",
      "Requirement already satisfied: pygments in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython->nb_black) (2.10.0)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython->nb_black) (0.1.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jedi>=0.16->ipython->nb_black) (0.8.2)\n",
      "Requirement already satisfied: wcwidth in c:\\programdata\\anaconda3\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->nb_black) (0.2.5)\n"
     ]
    }
   ],
   "source": [
    "pip install nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ef5a3fc3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The nb_black extension is already loaded. To reload it, use:\n",
      "  %reload_ext nb_black\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 39;\n",
       "                var nbb_unformatted_code = \"import vk\\nimport time\\nimport pandas as pd\\n\\nimport json\\nimport requests\\nimport folium\\nimport math\\nimport datetime as dt\\nimport os\\nimport re\\nimport random\\nimport pymorphy2\\nimport urllib\\n\\nimport warnings\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\\n\\npd.options.display.max_colwidth = 1000\\nfrom datetime import datetime, date\\nimport seaborn as sns\\nimport numpy as np\\nfrom scipy import stats\\nfrom collections import Counter\\nfrom transliterate import translit\\nfrom numpy import mean, std, var\\n\\nimport matplotlib.pyplot as plt\\n\\n%matplotlib inline\\n%config InlineBackend.figure_format='retina'\\n\\nimport re\\nimport string\\nfrom nltk.corpus import stopwords\\nimport nltk\\nfrom pymystem3 import Mystem\\nfrom string import punctuation\\nfrom wordcloud import WordCloud\\nimport ast\\nfrom scipy.stats.contingency import margins\\nfrom transformers import pipeline, AutoTokenizer, AutoModel\\nimport torch\\nimport transformers\\nimport umap\\nimport hdbscan\\nfrom sklearn.metrics import make_scorer\\nfrom sklearn.model_selection import GridSearchCV\\nimport logging\\n\\nlogging.captureWarnings(True)\\n%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"import vk\\nimport time\\nimport pandas as pd\\n\\nimport json\\nimport requests\\nimport folium\\nimport math\\nimport datetime as dt\\nimport os\\nimport re\\nimport random\\nimport pymorphy2\\nimport urllib\\n\\nimport warnings\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\\n\\npd.options.display.max_colwidth = 1000\\nfrom datetime import datetime, date\\nimport seaborn as sns\\nimport numpy as np\\nfrom scipy import stats\\nfrom collections import Counter\\nfrom transliterate import translit\\nfrom numpy import mean, std, var\\n\\nimport matplotlib.pyplot as plt\\n\\n%matplotlib inline\\n%config InlineBackend.figure_format='retina'\\n\\nimport re\\nimport string\\nfrom nltk.corpus import stopwords\\nimport nltk\\nfrom pymystem3 import Mystem\\nfrom string import punctuation\\nfrom wordcloud import WordCloud\\nimport ast\\nfrom scipy.stats.contingency import margins\\nfrom transformers import pipeline, AutoTokenizer, AutoModel\\nimport torch\\nimport transformers\\nimport umap\\nimport hdbscan\\nfrom sklearn.metrics import make_scorer\\nfrom sklearn.model_selection import GridSearchCV\\nimport logging\\n\\nlogging.captureWarnings(True)\\n%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import vk\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "import json\n",
    "import requests\n",
    "import folium\n",
    "import math\n",
    "import datetime as dt\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import pymorphy2\n",
    "import urllib\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pd.options.display.max_colwidth = 1000\n",
    "from datetime import datetime, date\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from collections import Counter\n",
    "from transliterate import translit\n",
    "from numpy import mean, std, var\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from pymystem3 import Mystem\n",
    "from string import punctuation\n",
    "from wordcloud import WordCloud\n",
    "import ast\n",
    "from scipy.stats.contingency import margins\n",
    "from transformers import pipeline, AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import transformers\n",
    "import umap\n",
    "import hdbscan\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import logging\n",
    "\n",
    "logging.captureWarnings(True)\n",
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da527db",
   "metadata": {},
   "source": [
    "## Data parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "67c5564d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 55;\n",
       "                var nbb_unformatted_code = \"# vk_api = vk.API(\\n#     access_token=\\\"vk1.a.eJNAwbeY3rLH2B8tTLlhg_q2AwyLM1m9VasVbfWs1wkdXDA8GR1ebwQduE5cYdenlPbmMxAjSwwd-mGdUVHBUQKwb8JZVd86QBgU9IsOYYmBQP_KKUEjmsHMDLZScEtATXYoJ4nBki7YXX0s6goyVWWva18TOkLIuZuSFM17eun7WYpWypFYaFT0GMopAgU0\\\"\\n# )\\nvk_api = vk.API(\\n    access_token=\\\"vk1.a.K1MtbuSo2VXLTRbD57CORalIq1rbG68HAeQTmqoTWr3sV94p4UaSPkPHRwpe5kJu0AzwRn62RfR9H7pPWXGLkL7GoHwpPThsqdZZ6X1sftx3VtamxAYpSZzI57Kmf6wGC-8RjAaOygWheNM8owPt8ZS-OzOcAVV3dTaAIw7zR6r24U_Aue46qtJpLDcE8w_nOqVQO0Qa8xAjFl4ahFhlUg\\\"\\n)\";\n",
       "                var nbb_formatted_code = \"# vk_api = vk.API(\\n#     access_token=\\\"vk1.a.eJNAwbeY3rLH2B8tTLlhg_q2AwyLM1m9VasVbfWs1wkdXDA8GR1ebwQduE5cYdenlPbmMxAjSwwd-mGdUVHBUQKwb8JZVd86QBgU9IsOYYmBQP_KKUEjmsHMDLZScEtATXYoJ4nBki7YXX0s6goyVWWva18TOkLIuZuSFM17eun7WYpWypFYaFT0GMopAgU0\\\"\\n# )\\nvk_api = vk.API(\\n    access_token=\\\"vk1.a.K1MtbuSo2VXLTRbD57CORalIq1rbG68HAeQTmqoTWr3sV94p4UaSPkPHRwpe5kJu0AzwRn62RfR9H7pPWXGLkL7GoHwpPThsqdZZ6X1sftx3VtamxAYpSZzI57Kmf6wGC-8RjAaOygWheNM8owPt8ZS-OzOcAVV3dTaAIw7zR6r24U_Aue46qtJpLDcE8w_nOqVQO0Qa8xAjFl4ahFhlUg\\\"\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# vk_api = vk.API(\n",
    "#     access_token=\"vk1.a.eJNAwbeY3rLH2B8tTLlhg_q2AwyLM1m9VasVbfWs1wkdXDA8GR1ebwQduE5cYdenlPbmMxAjSwwd-mGdUVHBUQKwb8JZVd86QBgU9IsOYYmBQP_KKUEjmsHMDLZScEtATXYoJ4nBki7YXX0s6goyVWWva18TOkLIuZuSFM17eun7WYpWypFYaFT0GMopAgU0\"\n",
    "# )\n",
    "vk_api = vk.API(\n",
    "    access_token=\"vk1.a.K1MtbuSo2VXLTRbD57CORalIq1rbG68HAeQTmqoTWr3sV94p4UaSPkPHRwpe5kJu0AzwRn62RfR9H7pPWXGLkL7GoHwpPThsqdZZ6X1sftx3VtamxAYpSZzI57Kmf6wGC-8RjAaOygWheNM8owPt8ZS-OzOcAVV3dTaAIw7zR6r24U_Aue46qtJpLDcE8w_nOqVQO0Qa8xAjFl4ahFhlUg\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62899ef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"list_of_groups = vk_api.groups.getById(\\n    v=5.131,\\n    group_ids=[\\n        \\\"rbc\\\",\\n        \\\"ria\\\",\\n        \\\"gazeta\\\",\\n        \\\"tv360\\\",\\n        \\\"lentaru\\\",\\n        \\\"kpru\\\",\\n        \\\"life\\\",\\n        \\\"m24\\\",\\n        \\\"snob_project\\\",\\n        \\\"knife.media\\\",\\n    ],\\n    fields=\\\"description\\\",\\n)\";\n",
       "                var nbb_formatted_code = \"list_of_groups = vk_api.groups.getById(\\n    v=5.131,\\n    group_ids=[\\n        \\\"rbc\\\",\\n        \\\"ria\\\",\\n        \\\"gazeta\\\",\\n        \\\"tv360\\\",\\n        \\\"lentaru\\\",\\n        \\\"kpru\\\",\\n        \\\"life\\\",\\n        \\\"m24\\\",\\n        \\\"snob_project\\\",\\n        \\\"knife.media\\\",\\n    ],\\n    fields=\\\"description\\\",\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "list_of_groups = vk_api.groups.getById(\n",
    "    v=5.131,\n",
    "    group_ids=[\n",
    "        \"rbc\",\n",
    "        \"ria\",\n",
    "        \"gazeta\",\n",
    "        \"tv360\",\n",
    "        \"lentaru\",\n",
    "        \"kpru\",\n",
    "        \"life\",\n",
    "        \"m24\",\n",
    "        \"snob_project\",\n",
    "        \"knife.media\",\n",
    "    ],\n",
    "    fields=\"description\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e9c1e68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"list_of_ids_groups = []\\nfor i in range(len(list_of_groups)):\\n    list_of_ids_groups.append(list_of_groups[i][\\\"id\\\"])\";\n",
       "                var nbb_formatted_code = \"list_of_ids_groups = []\\nfor i in range(len(list_of_groups)):\\n    list_of_ids_groups.append(list_of_groups[i][\\\"id\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "list_of_ids_groups = []\n",
    "for i in range(len(list_of_groups)):\n",
    "    list_of_ids_groups.append(list_of_groups[i][\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bcf5c8b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"list_of_ids_groups1 = list_of_ids_groups[:5]\\nlist_of_ids_groups2 = list_of_ids_groups[5:]\";\n",
       "                var nbb_formatted_code = \"list_of_ids_groups1 = list_of_ids_groups[:5]\\nlist_of_ids_groups2 = list_of_ids_groups[5:]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "list_of_ids_groups1 = list_of_ids_groups[:5]\n",
    "list_of_ids_groups2 = list_of_ids_groups[5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c39b5700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"time.sleep(3)\\ndf_escooter_1 = pd.DataFrame()\\nfor i in range(len(list_of_ids_groups1)):\\n    posts1 = vk_api.wall.search(\\n        v=5.131,\\n        owner_id=-list_of_ids_groups1[i],\\n        query=\\\"\\u044d\\u043b\\u0435\\u043a\\u0442\\u0440\\u043e\\u0441\\u0430\\u043c\\u043e\\u043a\\u0430\\u0442\\\",\\n        owners_only=1,\\n        count=100,\\n    )\\n    df_1 = pd.json_normalize(posts1[\\\"items\\\"])\\n    df_escooter_1 = pd.concat([df_1, df_escooter_1])\";\n",
       "                var nbb_formatted_code = \"time.sleep(3)\\ndf_escooter_1 = pd.DataFrame()\\nfor i in range(len(list_of_ids_groups1)):\\n    posts1 = vk_api.wall.search(\\n        v=5.131,\\n        owner_id=-list_of_ids_groups1[i],\\n        query=\\\"\\u044d\\u043b\\u0435\\u043a\\u0442\\u0440\\u043e\\u0441\\u0430\\u043c\\u043e\\u043a\\u0430\\u0442\\\",\\n        owners_only=1,\\n        count=100,\\n    )\\n    df_1 = pd.json_normalize(posts1[\\\"items\\\"])\\n    df_escooter_1 = pd.concat([df_1, df_escooter_1])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "time.sleep(3)\n",
    "df_escooter_1 = pd.DataFrame()\n",
    "for i in range(len(list_of_ids_groups1)):\n",
    "    posts1 = vk_api.wall.search(\n",
    "        v=5.131,\n",
    "        owner_id=-list_of_ids_groups1[i],\n",
    "        query=\"\",\n",
    "        owners_only=1,\n",
    "        count=100,\n",
    "    )\n",
    "    df_1 = pd.json_normalize(posts1[\"items\"])\n",
    "    df_escooter_1 = pd.concat([df_1, df_escooter_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "011d6a87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"time.sleep(3)\\ndf_escooter_2 = pd.DataFrame()\\nfor i in range(len(list_of_ids_groups2)):\\n    posts2 = vk_api.wall.search(\\n        v=5.131,\\n        owner_id=-list_of_ids_groups2[i],\\n        query=\\\"\\u044d\\u043b\\u0435\\u043a\\u0442\\u0440\\u043e\\u0441\\u0430\\u043c\\u043e\\u043a\\u0430\\u0442\\\",\\n        owners_only=1,\\n        count=100,\\n    )\\n    df_2 = pd.json_normalize(posts2[\\\"items\\\"])\\n    df_escooter_2 = pd.concat([df_2, df_escooter_2])\";\n",
       "                var nbb_formatted_code = \"time.sleep(3)\\ndf_escooter_2 = pd.DataFrame()\\nfor i in range(len(list_of_ids_groups2)):\\n    posts2 = vk_api.wall.search(\\n        v=5.131,\\n        owner_id=-list_of_ids_groups2[i],\\n        query=\\\"\\u044d\\u043b\\u0435\\u043a\\u0442\\u0440\\u043e\\u0441\\u0430\\u043c\\u043e\\u043a\\u0430\\u0442\\\",\\n        owners_only=1,\\n        count=100,\\n    )\\n    df_2 = pd.json_normalize(posts2[\\\"items\\\"])\\n    df_escooter_2 = pd.concat([df_2, df_escooter_2])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "time.sleep(3)\n",
    "df_escooter_2 = pd.DataFrame()\n",
    "for i in range(len(list_of_ids_groups2)):\n",
    "    posts2 = vk_api.wall.search(\n",
    "        v=5.131,\n",
    "        owner_id=-list_of_ids_groups2[i],\n",
    "        query=\"\",\n",
    "        owners_only=1,\n",
    "        count=100,\n",
    "    )\n",
    "    df_2 = pd.json_normalize(posts2[\"items\"])\n",
    "    df_escooter_2 = pd.concat([df_2, df_escooter_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0fd798bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"time.sleep(3)\\ndf_kicksharing_1 = pd.DataFrame()\\nfor i in range(len(list_of_ids_groups1)):\\n    posts3 = vk_api.wall.search(\\n        v=5.131,\\n        owner_id=-list_of_ids_groups1[i],\\n        query=\\\"\\u043a\\u0438\\u043a\\u0448\\u0435\\u0440\\u0438\\u043d\\u0433\\\",\\n        owners_only=1,\\n        count=100,\\n    )\\n    df_3 = pd.json_normalize(posts3[\\\"items\\\"])\\n    df_kicksharing_1 = pd.concat([df_3, df_kicksharing_1])\";\n",
       "                var nbb_formatted_code = \"time.sleep(3)\\ndf_kicksharing_1 = pd.DataFrame()\\nfor i in range(len(list_of_ids_groups1)):\\n    posts3 = vk_api.wall.search(\\n        v=5.131,\\n        owner_id=-list_of_ids_groups1[i],\\n        query=\\\"\\u043a\\u0438\\u043a\\u0448\\u0435\\u0440\\u0438\\u043d\\u0433\\\",\\n        owners_only=1,\\n        count=100,\\n    )\\n    df_3 = pd.json_normalize(posts3[\\\"items\\\"])\\n    df_kicksharing_1 = pd.concat([df_3, df_kicksharing_1])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "time.sleep(3)\n",
    "df_kicksharing_1 = pd.DataFrame()\n",
    "for i in range(len(list_of_ids_groups1)):\n",
    "    posts3 = vk_api.wall.search(\n",
    "        v=5.131,\n",
    "        owner_id=-list_of_ids_groups1[i],\n",
    "        query=\"\",\n",
    "        owners_only=1,\n",
    "        count=100,\n",
    "    )\n",
    "    df_3 = pd.json_normalize(posts3[\"items\"])\n",
    "    df_kicksharing_1 = pd.concat([df_3, df_kicksharing_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed1ad5ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"time.sleep(3)\\ndf_kicksharing_2 = pd.DataFrame()\\nfor i in range(len(list_of_ids_groups2)):\\n    posts4 = vk_api.wall.search(\\n        v=5.131,\\n        owner_id=-list_of_ids_groups2[i],\\n        query=\\\"\\u043a\\u0438\\u043a\\u0448\\u0435\\u0440\\u0438\\u043d\\u0433\\\",\\n        owners_only=1,\\n        count=100,\\n    )\\n    df_4 = pd.json_normalize(posts4[\\\"items\\\"])\\n    df_kicksharing_2 = pd.concat([df_4, df_kicksharing_2])\";\n",
       "                var nbb_formatted_code = \"time.sleep(3)\\ndf_kicksharing_2 = pd.DataFrame()\\nfor i in range(len(list_of_ids_groups2)):\\n    posts4 = vk_api.wall.search(\\n        v=5.131,\\n        owner_id=-list_of_ids_groups2[i],\\n        query=\\\"\\u043a\\u0438\\u043a\\u0448\\u0435\\u0440\\u0438\\u043d\\u0433\\\",\\n        owners_only=1,\\n        count=100,\\n    )\\n    df_4 = pd.json_normalize(posts4[\\\"items\\\"])\\n    df_kicksharing_2 = pd.concat([df_4, df_kicksharing_2])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "time.sleep(3)\n",
    "df_kicksharing_2 = pd.DataFrame()\n",
    "for i in range(len(list_of_ids_groups2)):\n",
    "    posts4 = vk_api.wall.search(\n",
    "        v=5.131,\n",
    "        owner_id=-list_of_ids_groups2[i],\n",
    "        query=\"\",\n",
    "        owners_only=1,\n",
    "        count=100,\n",
    "    )\n",
    "    df_4 = pd.json_normalize(posts4[\"items\"])\n",
    "    df_kicksharing_2 = pd.concat([df_4, df_kicksharing_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3606ebfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"time.sleep(3)\\ndf_rent_1 = pd.DataFrame()\\nfor i in range(len(list_of_ids_groups1)):\\n    posts5 = vk_api.wall.search(\\n        v=5.131,\\n        owner_id=-list_of_ids_groups1[i],\\n        query=\\\"\\u0430\\u0440\\u0435\\u043d\\u0434\\u0430 \\u0441\\u0430\\u043c\\u043e\\u043a\\u0430\\u0442\\\",\\n        owners_only=1,\\n        count=100,\\n    )\\n    df_5 = pd.json_normalize(posts5[\\\"items\\\"])\\n    df_rent_1 = pd.concat([df_5, df_rent_1])\";\n",
       "                var nbb_formatted_code = \"time.sleep(3)\\ndf_rent_1 = pd.DataFrame()\\nfor i in range(len(list_of_ids_groups1)):\\n    posts5 = vk_api.wall.search(\\n        v=5.131,\\n        owner_id=-list_of_ids_groups1[i],\\n        query=\\\"\\u0430\\u0440\\u0435\\u043d\\u0434\\u0430 \\u0441\\u0430\\u043c\\u043e\\u043a\\u0430\\u0442\\\",\\n        owners_only=1,\\n        count=100,\\n    )\\n    df_5 = pd.json_normalize(posts5[\\\"items\\\"])\\n    df_rent_1 = pd.concat([df_5, df_rent_1])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "time.sleep(3)\n",
    "df_rent_1 = pd.DataFrame()\n",
    "for i in range(len(list_of_ids_groups1)):\n",
    "    posts5 = vk_api.wall.search(\n",
    "        v=5.131,\n",
    "        owner_id=-list_of_ids_groups1[i],\n",
    "        query=\" \",\n",
    "        owners_only=1,\n",
    "        count=100,\n",
    "    )\n",
    "    df_5 = pd.json_normalize(posts5[\"items\"])\n",
    "    df_rent_1 = pd.concat([df_5, df_rent_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "28eb8894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"time.sleep(3)\\ndf_rent_2 = pd.DataFrame()\\nfor i in range(len(list_of_ids_groups2)):\\n    posts6 = vk_api.wall.search(\\n        v=5.131,\\n        owner_id=-list_of_ids_groups2[i],\\n        query=\\\"\\u0430\\u0440\\u0435\\u043d\\u0434\\u0430 \\u0441\\u0430\\u043c\\u043e\\u043a\\u0430\\u0442\\\",\\n        owners_only=1,\\n        count=100,\\n    )\\n    df_6 = pd.json_normalize(posts6[\\\"items\\\"])\\n    df_rent_2 = pd.concat([df_6, df_rent_2])\";\n",
       "                var nbb_formatted_code = \"time.sleep(3)\\ndf_rent_2 = pd.DataFrame()\\nfor i in range(len(list_of_ids_groups2)):\\n    posts6 = vk_api.wall.search(\\n        v=5.131,\\n        owner_id=-list_of_ids_groups2[i],\\n        query=\\\"\\u0430\\u0440\\u0435\\u043d\\u0434\\u0430 \\u0441\\u0430\\u043c\\u043e\\u043a\\u0430\\u0442\\\",\\n        owners_only=1,\\n        count=100,\\n    )\\n    df_6 = pd.json_normalize(posts6[\\\"items\\\"])\\n    df_rent_2 = pd.concat([df_6, df_rent_2])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "time.sleep(3)\n",
    "df_rent_2 = pd.DataFrame()\n",
    "for i in range(len(list_of_ids_groups2)):\n",
    "    posts6 = vk_api.wall.search(\n",
    "        v=5.131,\n",
    "        owner_id=-list_of_ids_groups2[i],\n",
    "        query=\" \",\n",
    "        owners_only=1,\n",
    "        count=100,\n",
    "    )\n",
    "    df_6 = pd.json_normalize(posts6[\"items\"])\n",
    "    df_rent_2 = pd.concat([df_6, df_rent_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc53e657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"df_rent_1[\\\"query\\\"] = \\\"\\u0430\\u0440\\u0435\\u043d\\u0434\\u0430 \\u0441\\u0430\\u043c\\u043e\\u043a\\u0430\\u0442\\\"\\ndf_rent_2[\\\"query\\\"] = \\\"\\u0430\\u0440\\u0435\\u043d\\u0434\\u0430 \\u0441\\u0430\\u043c\\u043e\\u043a\\u0430\\u0442\\\"\\ndf_kicksharing_1[\\\"query\\\"] = \\\"\\u043a\\u0438\\u043a\\u0448\\u0435\\u0440\\u0438\\u043d\\u0433\\\"\\ndf_kicksharing_2[\\\"query\\\"] = \\\"\\u043a\\u0438\\u043a\\u0448\\u0435\\u0440\\u0438\\u043d\\u0433\\\"\\ndf_escooter_1[\\\"query\\\"] = \\\"\\u044d\\u043b\\u0435\\u043a\\u0442\\u0440\\u043e\\u0441\\u0430\\u043c\\u043e\\u043a\\u0430\\u0442\\\"\\ndf_escooter_2[\\\"query\\\"] = \\\"\\u044d\\u043b\\u0435\\u043a\\u0442\\u0440\\u043e\\u0441\\u0430\\u043c\\u043e\\u043a\\u0430\\u0442\\\"\";\n",
       "                var nbb_formatted_code = \"df_rent_1[\\\"query\\\"] = \\\"\\u0430\\u0440\\u0435\\u043d\\u0434\\u0430 \\u0441\\u0430\\u043c\\u043e\\u043a\\u0430\\u0442\\\"\\ndf_rent_2[\\\"query\\\"] = \\\"\\u0430\\u0440\\u0435\\u043d\\u0434\\u0430 \\u0441\\u0430\\u043c\\u043e\\u043a\\u0430\\u0442\\\"\\ndf_kicksharing_1[\\\"query\\\"] = \\\"\\u043a\\u0438\\u043a\\u0448\\u0435\\u0440\\u0438\\u043d\\u0433\\\"\\ndf_kicksharing_2[\\\"query\\\"] = \\\"\\u043a\\u0438\\u043a\\u0448\\u0435\\u0440\\u0438\\u043d\\u0433\\\"\\ndf_escooter_1[\\\"query\\\"] = \\\"\\u044d\\u043b\\u0435\\u043a\\u0442\\u0440\\u043e\\u0441\\u0430\\u043c\\u043e\\u043a\\u0430\\u0442\\\"\\ndf_escooter_2[\\\"query\\\"] = \\\"\\u044d\\u043b\\u0435\\u043a\\u0442\\u0440\\u043e\\u0441\\u0430\\u043c\\u043e\\u043a\\u0430\\u0442\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_rent_1[\"query\"] = \" \"\n",
    "df_rent_2[\"query\"] = \" \"\n",
    "df_kicksharing_1[\"query\"] = \"\"\n",
    "df_kicksharing_2[\"query\"] = \"\"\n",
    "df_escooter_1[\"query\"] = \"\"\n",
    "df_escooter_2[\"query\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9659adf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"df_posts = pd.concat(\\n    [\\n        df_rent_1,\\n        df_rent_2,\\n        df_kicksharing_1,\\n        df_kicksharing_2,\\n        df_escooter_1,\\n        df_escooter_2,\\n    ]\\n)\";\n",
       "                var nbb_formatted_code = \"df_posts = pd.concat(\\n    [\\n        df_rent_1,\\n        df_rent_2,\\n        df_kicksharing_1,\\n        df_kicksharing_2,\\n        df_escooter_1,\\n        df_escooter_2,\\n    ]\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_posts = pd.concat(\n",
    "    [\n",
    "        df_rent_1,\n",
    "        df_rent_2,\n",
    "        df_kicksharing_1,\n",
    "        df_kicksharing_2,\n",
    "        df_escooter_1,\n",
    "        df_escooter_2,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "88291228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_unformatted_code = \"df_posts = df_posts.drop_duplicates(subset=\\\"id\\\")\";\n",
       "                var nbb_formatted_code = \"df_posts = df_posts.drop_duplicates(subset=\\\"id\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_posts = df_posts.drop_duplicates(subset=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "41ecfd9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"df_posts.to_csv('df_posts.csv', index=False)\";\n",
       "                var nbb_formatted_code = \"df_posts.to_csv(\\\"df_posts.csv\\\", index=False)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_posts.to_csv(\"df_posts.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b560e55b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"list_of_id_lists = []\\nfor i in range(len(list(df_posts.owner_id.unique()))):\\n    list_of_id_lists.append(\\n        list(\\n            df_posts[df_posts[\\\"owner_id\\\"] == list(df_posts.owner_id.unique())[i]][\\\"id\\\"]\\n        )\\n    )\";\n",
       "                var nbb_formatted_code = \"list_of_id_lists = []\\nfor i in range(len(list(df_posts.owner_id.unique()))):\\n    list_of_id_lists.append(\\n        list(\\n            df_posts[df_posts[\\\"owner_id\\\"] == list(df_posts.owner_id.unique())[i]][\\\"id\\\"]\\n        )\\n    )\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "list_of_id_lists = []\n",
    "for i in range(len(list(df_posts.owner_id.unique()))):\n",
    "    list_of_id_lists.append(\n",
    "        list(\n",
    "            df_posts[df_posts[\"owner_id\"] == list(df_posts.owner_id.unique())[i]][\"id\"]\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a7171102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"list_of_owner_ids = list(df_posts.owner_id.unique())\";\n",
       "                var nbb_formatted_code = \"list_of_owner_ids = list(df_posts.owner_id.unique())\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "list_of_owner_ids = list(df_posts.owner_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "85f8e9d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"df1 = pd.DataFrame()\\ndf3 = pd.DataFrame()\\nfor i in range(len(list_of_owner_ids)):\\n    for j in range(len(list_of_id_lists[i])):\\n        time.sleep(3)\\n        get_comments = vk_api.wall.getComments(v=5.131,\\n                                      owner_id = list_of_owner_ids[i],\\n                                      post_id = list_of_id_lists[i][j],\\n                                      need_likes = 1,\\n                                      count = 100,\\n                                      preview_length = 0,\\n                                      extended = 1,\\n                                      thread_items_count = 10,\\n                                      fields = ['bdate', 'city', 'home_town'])\\n        df2 = pd.json_normalize(get_comments[\\\"items\\\"])\\n        df4 = pd.json_normalize(get_comments[\\\"profiles\\\"])\\n        df1 = pd.concat([df1, df2])\\n        df3 = pd.concat([df3, df4])\";\n",
       "                var nbb_formatted_code = \"df1 = pd.DataFrame()\\ndf3 = pd.DataFrame()\\nfor i in range(len(list_of_owner_ids)):\\n    for j in range(len(list_of_id_lists[i])):\\n        time.sleep(3)\\n        get_comments = vk_api.wall.getComments(\\n            v=5.131,\\n            owner_id=list_of_owner_ids[i],\\n            post_id=list_of_id_lists[i][j],\\n            need_likes=1,\\n            count=100,\\n            preview_length=0,\\n            extended=1,\\n            thread_items_count=10,\\n            fields=[\\\"bdate\\\", \\\"city\\\", \\\"home_town\\\"],\\n        )\\n        df2 = pd.json_normalize(get_comments[\\\"items\\\"])\\n        df4 = pd.json_normalize(get_comments[\\\"profiles\\\"])\\n        df1 = pd.concat([df1, df2])\\n        df3 = pd.concat([df3, df4])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df1 = pd.DataFrame()\n",
    "df3 = pd.DataFrame()\n",
    "for i in range(len(list_of_owner_ids)):\n",
    "    for j in range(len(list_of_id_lists[i])):\n",
    "        time.sleep(3)\n",
    "        get_comments = vk_api.wall.getComments(\n",
    "            v=5.131,\n",
    "            owner_id=list_of_owner_ids[i],\n",
    "            post_id=list_of_id_lists[i][j],\n",
    "            need_likes=1,\n",
    "            count=100,\n",
    "            preview_length=0,\n",
    "            extended=1,\n",
    "            thread_items_count=10,\n",
    "            fields=[\"bdate\", \"city\", \"home_town\"],\n",
    "        )\n",
    "        df2 = pd.json_normalize(get_comments[\"items\"])\n",
    "        df4 = pd.json_normalize(get_comments[\"profiles\"])\n",
    "        df1 = pd.concat([df1, df2])\n",
    "        df3 = pd.concat([df3, df4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "06ce39db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"df1.to_csv('comments.csv', index=False)\";\n",
       "                var nbb_formatted_code = \"df1.to_csv(\\\"comments.csv\\\", index=False)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df1.to_csv(\"comments.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ae3c991f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"df3.to_csv('people.csv', index=False)\";\n",
       "                var nbb_formatted_code = \"df3.to_csv(\\\"people.csv\\\", index=False)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df3.to_csv(\"people.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3f5af9d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"comments = pd.read_csv('comments.csv')\";\n",
       "                var nbb_formatted_code = \"comments = pd.read_csv(\\\"comments.csv\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "comments = pd.read_csv(\"comments.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3a519b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 31;\n",
       "                var nbb_unformatted_code = \"df_threads = pd.DataFrame()\\nfor i in comments['thread.items'].index:\\n    thread = ast.literal_eval(comments['thread.items'][i])\\n    df_thred = pd.json_normalize(thread)\\n    df_threads = pd.concat([df_thred, df_threads])\";\n",
       "                var nbb_formatted_code = \"df_threads = pd.DataFrame()\\nfor i in comments[\\\"thread.items\\\"].index:\\n    thread = ast.literal_eval(comments[\\\"thread.items\\\"][i])\\n    df_thred = pd.json_normalize(thread)\\n    df_threads = pd.concat([df_thred, df_threads])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_threads = pd.DataFrame()\n",
    "for i in comments[\"thread.items\"].index:\n",
    "    thread = ast.literal_eval(comments[\"thread.items\"][i])\n",
    "    df_thred = pd.json_normalize(thread)\n",
    "    df_threads = pd.concat([df_thred, df_threads])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1f6286dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 32;\n",
       "                var nbb_unformatted_code = \"df_threads = df_threads.reset_index(drop=True)\";\n",
       "                var nbb_formatted_code = \"df_threads = df_threads.reset_index(drop=True)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_threads = df_threads.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c4a5986b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 33;\n",
       "                var nbb_unformatted_code = \"df_threads = df_threads[1770:]\";\n",
       "                var nbb_formatted_code = \"df_threads = df_threads[1770:]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_threads = df_threads[1770:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bb5f22ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 34;\n",
       "                var nbb_unformatted_code = \"df_threads = df_threads.reset_index(drop=True)\";\n",
       "                var nbb_formatted_code = \"df_threads = df_threads.reset_index(drop=True)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_threads = df_threads.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f0cf5def",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 35;\n",
       "                var nbb_unformatted_code = \"df_threads = df_threads[802:]\\ndf_threads = df_threads.reset_index(drop=True)\";\n",
       "                var nbb_formatted_code = \"df_threads = df_threads[802:]\\ndf_threads = df_threads.reset_index(drop=True)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_threads = df_threads[802:]\n",
    "df_threads = df_threads.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ac915c65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 36;\n",
       "                var nbb_unformatted_code = \"df_threads.to_csv('df_threads.csv', index=False)\";\n",
       "                var nbb_formatted_code = \"df_threads.to_csv(\\\"df_threads.csv\\\", index=False)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_threads.to_csv(\"df_threads.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "21547d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>from_id</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>post_id</th>\n",
       "      <th>owner_id</th>\n",
       "      <th>parents_stack</th>\n",
       "      <th>reply_to_user</th>\n",
       "      <th>reply_to_comment</th>\n",
       "      <th>likes.can_like</th>\n",
       "      <th>likes.count</th>\n",
       "      <th>likes.user_likes</th>\n",
       "      <th>attachments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1993293</td>\n",
       "      <td>242784501</td>\n",
       "      <td>1625629520</td>\n",
       "      <td>[id172507971|],  .</td>\n",
       "      <td>1992810</td>\n",
       "      <td>-35068738</td>\n",
       "      <td>[1992945]</td>\n",
       "      <td>172507971</td>\n",
       "      <td>1993231</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1992955</td>\n",
       "      <td>174406062</td>\n",
       "      <td>1625601622</td>\n",
       "      <td>[id30122036|],       .</td>\n",
       "      <td>1992810</td>\n",
       "      <td>-35068738</td>\n",
       "      <td>[1992939]</td>\n",
       "      <td>30122036</td>\n",
       "      <td>1992939</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1992960</td>\n",
       "      <td>174869583</td>\n",
       "      <td>1625601686</td>\n",
       "      <td>[id30122036|],         )</td>\n",
       "      <td>1992810</td>\n",
       "      <td>-35068738</td>\n",
       "      <td>[1992939]</td>\n",
       "      <td>30122036</td>\n",
       "      <td>1992939</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1992999</td>\n",
       "      <td>10374286</td>\n",
       "      <td>1625602692</td>\n",
       "      <td>[id30122036|],          ,     .</td>\n",
       "      <td>1992810</td>\n",
       "      <td>-35068738</td>\n",
       "      <td>[1992939]</td>\n",
       "      <td>30122036</td>\n",
       "      <td>1992939</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1993152</td>\n",
       "      <td>153172644</td>\n",
       "      <td>1625607242</td>\n",
       "      <td>[id174406062|],     </td>\n",
       "      <td>1992810</td>\n",
       "      <td>-35068738</td>\n",
       "      <td>[1992939]</td>\n",
       "      <td>174406062</td>\n",
       "      <td>1992955</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id    from_id        date  \\\n",
       "0  1993293  242784501  1625629520   \n",
       "1  1992955  174406062  1625601622   \n",
       "2  1992960  174869583  1625601686   \n",
       "3  1992999   10374286  1625602692   \n",
       "4  1993152  153172644  1625607242   \n",
       "\n",
       "                                                                                                                               text  \\\n",
       "0                                                                                              [id172507971|],  .   \n",
       "1                                                         [id30122036|],       .   \n",
       "2                                                              [id30122036|],         )   \n",
       "3  [id30122036|],          ,     .   \n",
       "4                                                                     [id174406062|],        \n",
       "\n",
       "   post_id  owner_id parents_stack  reply_to_user  reply_to_comment  \\\n",
       "0  1992810 -35068738     [1992945]      172507971           1993231   \n",
       "1  1992810 -35068738     [1992939]       30122036           1992939   \n",
       "2  1992810 -35068738     [1992939]       30122036           1992939   \n",
       "3  1992810 -35068738     [1992939]       30122036           1992939   \n",
       "4  1992810 -35068738     [1992939]      174406062           1992955   \n",
       "\n",
       "   likes.can_like  likes.count  likes.user_likes attachments  \n",
       "0               0            0                 0         NaN  \n",
       "1               0            5                 0         NaN  \n",
       "2               0            4                 0         NaN  \n",
       "3               0            8                 0         NaN  \n",
       "4               0            1                 0         NaN  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 40;\n",
       "                var nbb_unformatted_code = \"folder_url = \\\"https://disk.yandex.ru/d/6hIRr2dWujInjg\\\"\\nfile_url = \\\"df_threads.csv\\\"\\nurl = (\\n    \\\"https://cloud-api.yandex.net/v1/disk/public/resources/download\\\"\\n    + \\\"?public_key=\\\"\\n    + urllib.parse.quote(folder_url)\\n    + \\\"&path=/\\\"\\n    + urllib.parse.quote(file_url)\\n)\\n\\nr = requests.get(url)  # \\u0437\\u0430\\u043f\\u0440\\u043e\\u0441 \\u0441\\u0441\\u044b\\u043b\\u043a\\u0438 \\u043d\\u0430 \\u0441\\u043a\\u0430\\u0447\\u0438\\u0432\\u0430\\u043d\\u0438\\u0435\\nh = json.loads(r.text)[\\\"href\\\"]  # '\\u043f\\u0430\\u0440\\u0441\\u0438\\u043d\\u0433' \\u0441\\u0441\\u044b\\u043b\\u043a\\u0438 \\u043d\\u0430 \\u0441\\u043a\\u0430\\u0447\\u0438\\u0432\\u0430\\u043d\\u0438\\u0435\\n\\ndf_threads = pd.read_csv(h, sep=\\\",\\\", error_bad_lines=False, comment=\\\"#\\\")\\ndf_threads.head()\";\n",
       "                var nbb_formatted_code = \"folder_url = \\\"https://disk.yandex.ru/d/6hIRr2dWujInjg\\\"\\nfile_url = \\\"df_threads.csv\\\"\\nurl = (\\n    \\\"https://cloud-api.yandex.net/v1/disk/public/resources/download\\\"\\n    + \\\"?public_key=\\\"\\n    + urllib.parse.quote(folder_url)\\n    + \\\"&path=/\\\"\\n    + urllib.parse.quote(file_url)\\n)\\n\\nr = requests.get(url)  # \\u0437\\u0430\\u043f\\u0440\\u043e\\u0441 \\u0441\\u0441\\u044b\\u043b\\u043a\\u0438 \\u043d\\u0430 \\u0441\\u043a\\u0430\\u0447\\u0438\\u0432\\u0430\\u043d\\u0438\\u0435\\nh = json.loads(r.text)[\\\"href\\\"]  # '\\u043f\\u0430\\u0440\\u0441\\u0438\\u043d\\u0433' \\u0441\\u0441\\u044b\\u043b\\u043a\\u0438 \\u043d\\u0430 \\u0441\\u043a\\u0430\\u0447\\u0438\\u0432\\u0430\\u043d\\u0438\\u0435\\n\\ndf_threads = pd.read_csv(h, sep=\\\",\\\", error_bad_lines=False, comment=\\\"#\\\")\\ndf_threads.head()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "folder_url = \"https://disk.yandex.ru/d/6hIRr2dWujInjg\"\n",
    "file_url = \"df_threads.csv\"\n",
    "url = (\n",
    "    \"https://cloud-api.yandex.net/v1/disk/public/resources/download\"\n",
    "    + \"?public_key=\"\n",
    "    + urllib.parse.quote(folder_url)\n",
    "    + \"&path=/\"\n",
    "    + urllib.parse.quote(file_url)\n",
    ")\n",
    "\n",
    "r = requests.get(url)  #    \n",
    "h = json.loads(r.text)[\"href\"]  # ''   \n",
    "\n",
    "df_threads = pd.read_csv(h, sep=\",\", error_bad_lines=False, comment=\"#\")\n",
    "df_threads.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a493e86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_threads_ = pd.DataFrame()\n",
    "for i in range(len(df_threads[\"id\"])):\n",
    "    time.sleep(3)\n",
    "    get_comments = vk_api.wall.getComment(\n",
    "        v=5.131,\n",
    "        owner_id=df_threads[\"owner_id\"][i],\n",
    "        comment_id=df_threads[\"id\"][i],\n",
    "        extended=1,\n",
    "        fields=[\"bdate\", \"city\", \"home_town\"],\n",
    "    )\n",
    "    df_threads_1 = pd.json_normalize(get_comments[\"profiles\"])\n",
    "    df_threads_ = pd.concat([df_threads_, df_threads_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5d818a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_threads_.to_csv('people_threads_part3.csv', index=False)\n",
    "df_threads_.to_csv('people_threads_part2.csv', index=False)\n",
    "df_threads_.to_csv('people_threads_part2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786daa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = pd.read_csv(\"df_posts.csv\")\n",
    "comments = pd.read_csv(\"comments.csv\")\n",
    "people = pd.read_csv(\"people.csv\")\n",
    "threads = pd.read_csv(\"df_threads.csv\")\n",
    "people_threads = pd.read_csv(\"df_threads.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d116f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [posts, comments, people, threads, people_threads]:\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c4e824",
   "metadata": {},
   "source": [
    "## Describe a social portrait of people commenting on kicksharing posts in VK publics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782d6f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenating information about the main commentators + commentators from the thread\n",
    "all_people = pd.concat([people, people_threads])\n",
    "all_people = all_people[~all_people.last_name.isna()]\n",
    "all_people.drop_duplicates(inplace=True)\n",
    "# remove deleted and blocked users\n",
    "all_people = all_people[~all_people.deactivated.isin([\"banned\", \"deleted\"])]\n",
    "# there are several problems with age  missing data and the absence of a year in the data\n",
    "# let's take the minimum age value in terms of the number of characters and filter out those who have age data\n",
    "all_people_with_age = all_people[\n",
    "    all_people.bdate.apply(lambda x: len(str(x))) >= len(\"7.1.1985\")\n",
    "]\n",
    "#  find those who have no age or it is without a year\n",
    "all_people_without_age = all_people[\n",
    "    all_people.bdate.apply(lambda x: len(str(x))) < len(\"7.1.1985\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f7c45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_list = list(all_people_with_age.bdate)\n",
    "# Since the age format is str, it needs to be converted to datetime.\n",
    "for i in range(len(age_list)):\n",
    "    if (age_list[i].find(\".\") == 1) & (\n",
    "        age_list[i].find(\".\", age_list[i].find(\".\") + 1) == 3\n",
    "    ):\n",
    "        age_list[i] = \"0\" + age_list[i]\n",
    "        age_list[i] = age_list[i][:3] + \"0\" + age_list[i][3:]\n",
    "\n",
    "    if (age_list[i].find(\".\") == 1) & (\n",
    "        age_list[i].find(\".\", age_list[i].find(\".\") + 1) == 4\n",
    "    ):\n",
    "        age_list[i] = \"0\" + age_list[i]\n",
    "\n",
    "    if (age_list[i].find(\".\") == 2) & (\n",
    "        (age_list[i].find(\".\", age_list[i].find(\".\") + 1)) == 4\n",
    "    ):\n",
    "        age_list[i] = age_list[i][:3] + \"0\" + age_list[i][3:]\n",
    "\n",
    "    if (age_list[i].find(\".\") == 1) & (\n",
    "        age_list[i].find(\".\", age_list[i].find(\".\") + 1) == 4\n",
    "    ):\n",
    "        age_list[i] = \"0\" + age_list[i]\n",
    "\n",
    "all_people_with_age.insert(loc=1, column=\"age\", value=age_list)\n",
    "\n",
    "all_people_with_age[\"age_len\"] = all_people_with_age.age.apply(lambda x: len(str(x)))\n",
    "all_people_with_age.age = all_people_with_age.age.apply(\n",
    "    lambda x: datetime.strptime(x, \"%d.%m.%Y\")\n",
    ")\n",
    "\n",
    "\n",
    "def calculate_age(born):\n",
    "    today = date.today()\n",
    "    return today.year - born.year - ((today.month, today.day) < (born.month, born.day))\n",
    "\n",
    "\n",
    "all_people_with_age[\"age_years\"] = all_people_with_age.age.apply(\n",
    "    lambda x: calculate_age(x)\n",
    ")\n",
    "all_people_with_age = all_people_with_age.reset_index(drop=True)\n",
    "sns.boxplot(all_people_with_age[\"age_years\"], palette=\"Set3\").set(\n",
    "    xlabel=\",  \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b75fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The graph shows that there are outliers in the data.\n",
    "# Let's apply the z-criteria in order to identify the index of people with an outlier age.\n",
    "z = np.abs(stats.zscore(all_people_with_age[\"age_years\"]))\n",
    "threshold = 3\n",
    "outliers_age = list((np.where(z > 3))[0])\n",
    "\n",
    "# Let's remove outliers from the data and calculate the median\n",
    "all_people_with_age_without_outliers = all_people_with_age[\n",
    "    ~all_people_with_age.index.isin(outliers_age)\n",
    "]\n",
    "print(f\"Median age is {all_people_with_age_without_outliers.age_years.median()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952129d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the age of people with the age-outlier by the median and calculate the median for all people with age\n",
    "all_people_with_age.loc[\n",
    "    outliers_age, \"age_years\"\n",
    "] = all_people_with_age_without_outliers.age_years.median()\n",
    "print(f\"Median age for people with age is {all_people_with_age.age_years.median()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55b6da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_people_with_age.age_years.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cf038d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get the final dataset with the correct age for all users\n",
    "all_people_without_age[\"age_years\"] = all_people_with_age.age_years.median()\n",
    "all_people_clear_age = pd.concat([all_people_without_age, all_people_with_age])\n",
    "all_people_clear_age.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75f4563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's determine the gender of a person using a database of fake names and gender.\n",
    "# We will also add names and surnames translated to the dataset.\n",
    "dfru = pd.read_csv(\"FakeNameGenerator.com_de68fd01.csv\")\n",
    "list_of_translit_names = []\n",
    "for i in dfru.GivenName.index:\n",
    "    list_of_translit_names.append(\n",
    "        translit(dfru.GivenName[i], language_code=\"ru\", reversed=True)\n",
    "    )\n",
    "\n",
    "list_of_translit_surnames = []\n",
    "for i in dfru.Surname.index:\n",
    "    list_of_translit_surnames.append(\n",
    "        translit(dfru.Surname[i], language_code=\"ru\", reversed=True)\n",
    "    )\n",
    "\n",
    "df_of_translit_names = pd.DataFrame(list_of_translit_names)\n",
    "df_of_translit_surnames = pd.DataFrame(list_of_translit_surnames)\n",
    "\n",
    "df_of_translit_names = df_of_translit_names.rename(columns={0: \"GivenName\"})\n",
    "df_of_translit_surnames = df_of_translit_surnames.rename(columns={0: \"Surname\"})\n",
    "\n",
    "df_translit = pd.concat([df_of_translit_names, df_of_translit_surnames], axis=1)\n",
    "df_translit = pd.concat([df_translit, dfru[\"Gender\"]], axis=1)\n",
    "\n",
    "dfru = pd.concat([dfru, df_translit])\n",
    "dfru = dfru.reset_index(drop=True)\n",
    "\n",
    "# Let's also take an additional dataset and add a translit to it\n",
    "\n",
    "df2 = pd.read_csv(\"russian_names.csv\", sep=\";\")\n",
    "\n",
    "dict1 = {\"\": \"female\", \"\": \"male\"}\n",
    "df2[\"Gender\"] = df2.Sex.apply(lambda x: dict1[x])\n",
    "\n",
    "df2 = df2[[\"Name\", \"Gender\"]]\n",
    "df2 = df2.rename(columns={\"Name\": \"GivenName\"})\n",
    "\n",
    "list_of_translit_names2 = []\n",
    "for i in df2.GivenName.index:\n",
    "    list_of_translit_names2.append(\n",
    "        translit(df2.GivenName[i], language_code=\"ru\", reversed=True)\n",
    "    )\n",
    "df_of_translit_names2 = pd.DataFrame(list_of_translit_names2)\n",
    "df_of_translit_names2 = df_of_translit_names2.rename(columns={0: \"GivenName\"})\n",
    "df_translit2 = pd.concat([df_of_translit_names2, df2[\"Gender\"]], axis=1)\n",
    "\n",
    "df2 = pd.concat([df2, df_translit2])\n",
    "df2 = df2.reset_index(drop=True)\n",
    "\n",
    "dfru = pd.concat([dfru, df2])\n",
    "\n",
    "# Let's also take a dataset with foreign names\n",
    "\n",
    "df3 = pd.read_csv(\"foreign_names.csv\", sep=\";\")\n",
    "\n",
    "df3 = df3[[\"name\", \"gender\"]]\n",
    "df3 = df3.rename(columns={\"name\": \"GivenName\", \"gender\": \"Gender\"})\n",
    "\n",
    "dfru = pd.concat([dfru, df3])\n",
    "dfru.Surname = dfru.Surname.fillna(\"x\")\n",
    "dfru.Gender = dfru.Gender.apply(lambda x: x.lower())\n",
    "\n",
    "# Let's create words with female and male names and the endings of surnames\n",
    "\n",
    "rumalenames = set(dfru[dfru[\"Gender\"] == \"male\"][\"GivenName\"])\n",
    "rumalesurnames = set(s[-3:] for s in dfru[dfru[\"Gender\"] == \"male\"][\"Surname\"])\n",
    "\n",
    "rufemalenames = set(dfru[dfru[\"Gender\"] == \"female\"][\"GivenName\"])\n",
    "rufemalesurnames = set(s[-3:] for s in dfru[dfru[\"Gender\"] == \"female\"][\"Surname\"])\n",
    "\n",
    "# Let's determine the gender of a person\n",
    "list_gender = []\n",
    "\n",
    "for i in all_people_clear_age.index:\n",
    "    name = all_people_clear_age[\"first_name\"][i]\n",
    "    surname = all_people_clear_age[\"last_name\"][i]\n",
    "    if (name in rumalenames) or (surname in rumalesurnames):\n",
    "        list_gender.append(\"m\")\n",
    "    elif (name in rufemalenames) or (surname in rufemalesurnames):\n",
    "        list_gender.append(\"f\")\n",
    "    else:\n",
    "        list_gender.append(\"unk\")\n",
    "\n",
    "Counter(list_gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2db80ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's add a column with the gender to the dataset, and also try to check the surnames in the name and vice versa\n",
    "df_g = pd.DataFrame(list_gender)\n",
    "df_g = df_g.rename(columns={0: \"gen\"})\n",
    "all_people_clear_age_gen0 = pd.concat([all_people_clear_age, df_g], axis=1)\n",
    "all_people_clear_age_gen0_unk = all_people_clear_age_gen0[\n",
    "    all_people_clear_age_gen0.gen == \"unk\"\n",
    "]\n",
    "all_people_clear_age_gen0_unk = all_people_clear_age_gen0_unk.drop(\n",
    "    all_people_clear_age_gen0_unk.columns[26], axis=1\n",
    ")\n",
    "all_people_clear_age_gen0_unk = all_people_clear_age_gen0_unk.reset_index(drop=True)\n",
    "\n",
    "list_gender2 = []\n",
    "\n",
    "for i in all_people_clear_age_gen0_unk.index:\n",
    "    name = all_people_clear_age_gen0_unk[\"first_name\"][i]\n",
    "    surname = all_people_clear_age_gen0_unk[\"last_name\"][i]\n",
    "    if (surname in rumalenames) or (name in rumalesurnames):\n",
    "        list_gender2.append(\"m\")\n",
    "    elif (surname in rufemalenames) or (name in rufemalesurnames):\n",
    "        list_gender2.append(\"f\")\n",
    "    else:\n",
    "        list_gender2.append(\"unk\")\n",
    "\n",
    "Counter(list_gender2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65172826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since unk is only about 6% of the gender of all users, we will calculate and replace them with mode\n",
    "df_g2 = pd.DataFrame(list_gender2)\n",
    "df_g2 = df_g2.rename(columns={0: \"gen\"})\n",
    "all_people_clear_age_gen1 = pd.concat([all_people_clear_age_gen0_unk, df_g2], axis=1)\n",
    "all_people_clear_age_gen0_not_unk = all_people_clear_age_gen0[\n",
    "    all_people_clear_age_gen0.gen != \"unk\"\n",
    "]\n",
    "df_age_middle = pd.concat(\n",
    "    [all_people_clear_age_gen0_not_unk, all_people_clear_age_gen1]\n",
    ")\n",
    "print(f\"Mode of gender is {df_age_middle.gen.mode()[0]} (man)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c8f626",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict3 = {\"unk\": \"m\", \"m\": \"m\", \"f\": \"f\"}\n",
    "df_age_middle[\"gen\"] = df_age_middle[\"gen\"].apply(lambda x: dict3[x])\n",
    "print(df_age_middle[\"gen\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a047813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the distribution by city\n",
    "print(df_age_middle[\"city.title\"].isna().value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afaf815b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_age_middle[\"home_town\"].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76dd5b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_age_middle[\"city\"] = df_age_middle[\"city.title\"].fillna(df_age_middle[\"home_town\"])\n",
    "df_age_middle[\"city\"].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07e506b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_age_middle[\"city\"] = df_age_middle[\"city\"].apply(lambda x: str(x).lower())\n",
    "print(f'Mode of the city is {df_age_middle[\"city\"].mode()[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2631d313",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_age_middle = df_age_middle.reset_index(drop=True)\n",
    "df_city_nan = df_age_middle[df_age_middle.city == \"nan\"]\n",
    "df_city_ = df_age_middle[df_age_middle.city != \"nan\"]\n",
    "dict4 = {\"nan\": \"\"}\n",
    "df_city_nan[\"city\"] = df_city_nan[\"city\"].apply(lambda x: dict4[x])\n",
    "people_final = pd.concat([df_city_nan, df_city_])\n",
    "people_final.to_csv(\"people_final.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5481482b",
   "metadata": {},
   "outputs": [],
   "source": [
    "people_final = people_final[\n",
    "    [\n",
    "        \"id\",\n",
    "        \"first_name\",\n",
    "        \"last_name\",\n",
    "        \"can_access_closed\",\n",
    "        \"bdate\",\n",
    "        \"city.title\",\n",
    "        \"home_town\",\n",
    "        \"age_years\",\n",
    "        \"gen\",\n",
    "        \"city\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "people_final[\"gen\"].unique()\n",
    "\n",
    "dict5 = {\"f\": \"\", \"m\": \"\"}\n",
    "people_final[\"gen\"] = people_final[\"gen\"].apply(lambda x: dict5[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b15bc7",
   "metadata": {},
   "source": [
    "### Gender distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1068cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "people_final[\"gen\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e90374",
   "metadata": {},
   "outputs": [],
   "source": [
    "people_final[\"gen\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09add98",
   "metadata": {},
   "source": [
    "*Since the gender variable is measured on a nominal scale, mode is used as a measure of the central trend, and the spread measure is the coefficient of qualitative variation.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f13b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "people_final[\"gen\"].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd5662c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict6 = {\"\": 1, \"\": 0}\n",
    "people_final[\"gen_binary\"] = people_final[\"gen\"].apply(lambda x: dict6[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744cf292",
   "metadata": {},
   "outputs": [],
   "source": [
    "people_final[\"gen_binary\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa1f338",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4709\n",
    "k = 2\n",
    "n1 = people_final[\"gen_binary\"].value_counts()[0]\n",
    "n2 = people_final[\"gen_binary\"].value_counts()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1156cefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"The coefficient of qualitative variation is {((2 * k) / (n ** 2 * (k - 1))) * n1 * n2}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b298d4f9",
   "metadata": {},
   "source": [
    "*So, the coefficient of qualitative variation is 0.79. Thus, since the the coefficient of qualitative variation is close enough to 1, it means that from the point of view of the distribution by gender, the data are heterogeneous.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6b8b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(people_final[\"gen_binary\"].value_counts())\n",
    "labels = [\"\", \"\"]\n",
    "colors = sns.color_palette(\"Set2\")[0:5]\n",
    "plt.pie(data, labels=labels, colors=colors, autopct=\"%.0f%%\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89618996",
   "metadata": {},
   "source": [
    "### Age distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263581a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "people_final[\"age_years\"] = people_final[\"age_years\"].apply(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d422008",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = people_final[\"age_years\"].mean()\n",
    "print(f\"Mean age is {mean}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75194a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "median = people_final[\"age_years\"].median()\n",
    "print(f\"Median age is {median}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ef5c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = people_final[\"age_years\"].mode()\n",
    "print(f\"Mode age is {mode[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dce128c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Variance is {var(people_final[\"age_years\"])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18359ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Standart deviation is {std(people_final[\"age_years\"])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869ee42c",
   "metadata": {},
   "source": [
    "Therefore, the average age of users is within 38 +- 9.1 * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb122aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "RQ = people_final[\"age_years\"].describe()[6] - people_final[\"age_years\"].describe()[4]\n",
    "RQ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7edaf9",
   "metadata": {},
   "source": [
    "*RQ is 0, the age data is homogeneous*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0b4a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "std(people_final[\"age_years\"]) / people_final[\"age_years\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e01994",
   "metadata": {},
   "source": [
    "*Since the coefficient of variation does not exceed 30-35%, the age data are highly homogeneous.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e879d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(people_final[\"age_years\"]).set(xlabel=\",  \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f376081d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the statistics on data in which omissions and dates of birth were removed without specifying the year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18322b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_people_with_age[\"age_years\"] = all_people_with_age[\"age_years\"].apply(\n",
    "    lambda x: int(x)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd278759",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean2 = all_people_with_age[\"age_years\"].mean()\n",
    "print(f\"Mean age is {mean2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752c76bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "median2 = all_people_with_age[\"age_years\"].median()\n",
    "print(f\"Median age is {median2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4244fe59",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode2 = all_people_with_age[\"age_years\"].mode()\n",
    "print(f\"Mode age is {mode2[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0901715e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Variance is {var(all_people_with_age[\"age_years\"])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4d8093",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Standart deviation is {std(all_people_with_age[\"age_years\"])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05cf5875",
   "metadata": {},
   "source": [
    "*Therefore, the average age of users is within 40 +- 13.6 * 3*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4419b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "RQ = (\n",
    "    all_people_with_age[\"age_years\"].describe()[6]\n",
    "    - all_people_with_age[\"age_years\"].describe()[4]\n",
    ")\n",
    "RQ  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e1a12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "std(all_people_with_age[\"age_years\"]) / all_people_with_age[\"age_years\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfd1d46",
   "metadata": {},
   "source": [
    "*Since the coefficient of variation does not exceed 30-35%, the age data still have a high uniformity.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e836735f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(all_people_with_age[\"age_years\"], palette=\"pastel\").set(\n",
    "    xlabel=\",  \"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe93881",
   "metadata": {},
   "source": [
    "### City distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a153fa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(people_final[\"city\"].value_counts(normalize=True).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed70da6c",
   "metadata": {},
   "source": [
    "*Since the city variable is measured on a nominal scale, mode is used as a measure of the central trend, and the spread measure is the coefficient of qualitative variation.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead90851",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_city = people_final[\"city\"].mode()[0]\n",
    "print(f'Mode of the city is \"{mode_city}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdf6100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the coefficient of qualitative variation\n",
    "n = 4709\n",
    "k = 617\n",
    "numerator = (2 * k) / (n ** 2 * (k - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526cdfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "city_list = list(np.array(people_final[\"city\"].value_counts()))\n",
    "reverse_list = city_list[::-1]\n",
    "denominator = np.dot(city_list[:616][::-1], list(np.cumsum(reverse_list))[:616])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024e2a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerator * denominator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736d8cbc",
   "metadata": {},
   "source": [
    "**So, the coefficient of qualitative variationis 0.69. Thus, since the the coefficient of qualitative variation is close enough to 1, it means that from the point of view of the distribution by city, the data are heterogeneous.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84561fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is obvious that the distribution is heterogeneous due to filling in the gaps with a mode with the value \"Moscow\"\n",
    "# Let's look at the statistics on the data in which the omissions were removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3814e93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df_city_[\"city\"].value_counts(normalize=True).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523532ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_city = df_city_[\"city\"].mode()[0]\n",
    "print(f'Mode is \"{mode_city}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83e42c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the coefficient of qualitative variation\n",
    "n2 = 3477\n",
    "k2 = 617\n",
    "numerator2 = (2 * k2) / (n2 ** 2 * (k2 - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c28b8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "city_list2 = list(np.array(df_city_[\"city\"].value_counts()))\n",
    "reverse_list2 = city_list2[::-1]\n",
    "denominator2 = np.dot(city_list2[:616][::-1], list(np.cumsum(reverse_list2))[:616])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9aa36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerator2 * denominator2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070d6a78",
   "metadata": {},
   "source": [
    "So, the coefficient of qualitative variation is 0.84. Thus, since the coefficient of qualitative variation is close enough to 1, it means that from the point of view of gender distribution, the data became even more heterogeneous after the omissions were removed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b8454b",
   "metadata": {},
   "source": [
    "## Identify the most popular terms used in the discussion of the topic of kicksharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d55975",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "threads = threads.dropna(subset=\"text\")\n",
    "\n",
    "\n",
    "def comment_without_id(x):\n",
    "    try:\n",
    "        return x.split(\"],\")[1]\n",
    "    except:\n",
    "        return x.split(\"],\")[0]\n",
    "\n",
    "\n",
    "threads.text = threads.text.apply(lambda x: comment_without_id(x))\n",
    "\n",
    "threads = threads.dropna(subset=\"text\")\n",
    "threads = threads[threads.text != \"\"]\n",
    "\n",
    "all_comments = pd.concat([comments, threads]).dropna(subset=\"text\")\n",
    "all_comments.text = all_comments.text.apply(lambda x: x.lower()).apply(\n",
    "    lambda x: re.sub(r\"\\d+\", \"\", x)\n",
    ")\n",
    "all_comments = all_comments.reset_index(drop=True)\n",
    "all_comments[\"text_for_sentiment\"] = (\n",
    "    all_comments.text.apply(\n",
    "        lambda x: x.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    )\n",
    "    .apply(lambda x: x.strip().replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\"))\n",
    "    .apply(lambda x: re.sub(r\"\\n\", \"\", x))\n",
    ")\n",
    "\n",
    "mystem = Mystem()\n",
    "russian_stopwords = stopwords.words(\"russian\") + [\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "]\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    tokens = mystem.lemmatize(text.lower())\n",
    "    tokens = [\n",
    "        token\n",
    "        for token in tokens\n",
    "        if token not in russian_stopwords\n",
    "        and token != \" \"\n",
    "        and token.strip() not in punctuation\n",
    "        and token not in russian_stopwords\n",
    "    ]\n",
    "\n",
    "    text = \" \".join(tokens)\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def remove_emoji(string):\n",
    "    emoji_pattern = re.compile(\n",
    "        \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U00010000-\\U0010ffff\"\n",
    "        u\"\\u2640-\\u2642\"\n",
    "        u\"\\u2600-\\u2B55\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u23cf\"\n",
    "        u\"\\u23e9\"\n",
    "        u\"\\u231a\"\n",
    "        u\"\\ufe0f\"  # dingbats\n",
    "        u\"\\u3030\"\n",
    "        \"]+\",\n",
    "        flags=re.UNICODE,\n",
    "    )\n",
    "    return emoji_pattern.sub(r\"\", string)\n",
    "\n",
    "\n",
    "all_comments.text = all_comments.text.apply(lambda x: preprocess_text(remove_emoji(x)))\n",
    "all_comments = (\n",
    "    all_comments[all_comments.text != \"\"].dropna(subset=\"text\").reset_index(drop=True)\n",
    ")\n",
    "all_comments[\"text\"] = all_comments[\"text\"].apply(lambda x: str(x))\n",
    "clean = all_comments[\"text\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e53403",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"text.txt\", all_comments[\"text\"].values, delimiter=\" \", fmt=\"%s\")\n",
    "\n",
    "with open(\"clean_data.txt\", \"w\") as output:\n",
    "    output.write(str(clean)[2:-2])\n",
    "\n",
    "with open(\"text.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    stop_words = f.read().split()\n",
    "\n",
    "with open(\"text.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    words = f.read().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df912fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [word.replace(\"'\", \"\") for word in words]\n",
    "words = list(filter(lambda x: x != \"\", words))\n",
    "words = list(filter(lambda x: x != \"\", words))\n",
    "data = Counter(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53cddd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "background_color = \"#101010\"\n",
    "height = 720\n",
    "width = 1080\n",
    "\n",
    "word_cloud = WordCloud(background_color=background_color, width=width, height=height)\n",
    "\n",
    "word_cloud.generate_from_frequencies(data)\n",
    "\n",
    "word_cloud.to_file(\"image_11.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8640c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_comments.to_csv(\"data_before_.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2dc1e93",
   "metadata": {},
   "source": [
    "## To determine the sentiment of messages about the kicksharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5355ea72",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data_before_.csv\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d378da64",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"blanchefort/rubert-base-cased-sentiment\"\n",
    "classifier = pipeline(\"sentiment-analysis\", model=model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c72aadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data.text_for_sentiment.apply(lambda x: len(str(x))) < 512]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405bcdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sentiment_analysis_value'] = data['text_for_sentiment'].apply(lambda x: classifier(x)[0]['label'])\n",
    "data['sentiment_analysis_score'] = data['text_for_sentiment'].apply(lambda x: classifier(x)[0]['score'])\n",
    "data.to_csv('data_with_sentiment.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c99dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data_with_sentiment.csv\")\n",
    "print(data.sentiment_analysis_value.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edea679",
   "metadata": {},
   "source": [
    "## To identify whether the sentiment of the messages about the phenomenon depends on the tone of the news publication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278f0046",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_posts = posts[posts.text.isna()]\n",
    "missing_posts = missing_posts.dropna(subset=\"copy_history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353566f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_missing_posts = pd.DataFrame()\n",
    "for i in missing_posts[\"copy_history\"].index:\n",
    "    miss_post = ast.literal_eval(missing_posts[\"copy_history\"][i])\n",
    "    df_miss_post = pd.json_normalize(miss_post)\n",
    "    df_missing_posts = pd.concat([df_miss_post, df_missing_posts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48c549d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_missing_posts = df_missing_posts.set_index(missing_posts.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0018b780",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in missing_posts.index:\n",
    "    posts.text[i] = df_missing_posts.text[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770750c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = posts.dropna(subset=\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9529c7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "posts = posts.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d52645",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts.text = posts.text.apply(lambda x: x.lower())\n",
    "posts.text = posts.text.apply(lambda x: re.sub(r\"\\d+\", \"\", x))\n",
    "posts = posts.reset_index(drop=True)\n",
    "posts.text = posts.text.apply(\n",
    "    lambda x: x.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    ")\n",
    "posts.text = posts.text.apply(\n",
    "    lambda x: x.strip().replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\")\n",
    ")\n",
    "posts.text = posts.text.apply(lambda x: re.sub(r\"\\n\", \"\", x))\n",
    "posts.text = posts.text.apply(lambda x: re.sub(r\"\\n\", \"\", x))\n",
    "posts[\"text_for_sentiment\"] = posts.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062f631f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "posts.to_csv('posts_for_sentiment.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4b86dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "posts = pd.read_csv(\"posts_for_sentiment.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c5cdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts[\"len_of_post\"] = posts[\"text_for_sentiment\"].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af6d5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=posts, x=posts[\"len_of_post\"]).set(\n",
    "    xlabel=\"  \", ylabel=\" \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b6b400",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Median length of post {posts[\"len_of_post\"].median()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9f32b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f'Percentage of posts with length less that 512 is {posts[posts[\"len_of_post\"] < 512].shape[0] / posts.shape[0]}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8b8c4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "posts = posts[posts.text_for_sentiment.apply(lambda x: len(x)) < 512]\n",
    "posts['sentiment_analysis_value'] = posts['text_for_sentiment'].apply(lambda x: classifier(x)[0]['label'])\n",
    "posts['sentiment_analysis_score'] = posts['text_for_sentiment'].apply(lambda x: classifier(x)[0]['score'])\n",
    "posts.to_csv('posts_with_sentiment.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f51a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = pd.read_csv(\"posts_with_sentiment.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b95223e",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = posts.rename(\n",
    "    columns={\n",
    "        \"sentiment_analysis_value\": \"sentiment_analysis_value_post\",\n",
    "        \"sentiment_analysis_score\": \"sentiment_analysis_score_post\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e71b504",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(posts.sentiment_analysis_value_post.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85af46eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_with_sentiment_for_chi_square = posts[\n",
    "    [\"id\", \"sentiment_analysis_value_post\", \"sentiment_analysis_score_post\"]\n",
    "]\n",
    "posts_with_sentiment_for_chi_square_fot_dict = posts_with_sentiment_for_chi_square.set_index(\n",
    "    \"id\"\n",
    ")\n",
    "dict_posts = posts_with_sentiment_for_chi_square_fot_dict[\n",
    "    \"sentiment_analysis_value_post\"\n",
    "].to_dict()\n",
    "dict_posts_score = posts_with_sentiment_for_chi_square_fot_dict[\n",
    "    \"sentiment_analysis_score_post\"\n",
    "].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64103dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data[\n",
    "    data[\"post_id\"].isin(posts_with_sentiment_for_chi_square.id.unique())\n",
    "].reset_index(drop=True)\n",
    "data2.post_id = data2.post_id.apply(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fc49ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data_with_sentiment.csv\")\n",
    "data2[\"sentiment_post_value\"] = data2.post_id.apply(lambda x: dict_posts[x])\n",
    "data2[\"sentiment_post_score\"] = data2.post_id.apply(lambda x: dict_posts_score[x])\n",
    "crosstab1 = pd.crosstab(\n",
    "    data2[\"sentiment_post_value\"], data2[\"sentiment_analysis_value\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba5a670",
   "metadata": {},
   "outputs": [],
   "source": [
    "crosstab1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc22a138",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.chi2_contingency(crosstab1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747e2091",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2_without_neutral = data2[\n",
    "    (data2[\"sentiment_post_value\"] != \"NEUTRAL\")\n",
    "    & (data2[\"sentiment_analysis_value\"] != \"NEUTRAL\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7542608f",
   "metadata": {},
   "outputs": [],
   "source": [
    "crosstab_without_neutral = pd.crosstab(\n",
    "    data2_without_neutral[\"sentiment_post_value\"],\n",
    "    data2_without_neutral[\"sentiment_analysis_value\"],\n",
    ")\n",
    "crosstab_without_neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000dc1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.chi2_contingency(crosstab_without_neutral)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78bb20f",
   "metadata": {},
   "source": [
    "## To identify which factors contribute to the formation of opinions about kicksharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3297e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data_with_sentiment.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef393e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = list(data.text_for_sentiment)\n",
    "sentences_test1 = sentences[0:2000]\n",
    "sentences_test2 = sentences[2000:4000]\n",
    "sentences_test3 = sentences[4000:6000]\n",
    "sentences_test4 = sentences[6000:8000]\n",
    "sentences_test5 = sentences[8000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256ffe2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0]\n",
    "    input_mask_expanded = (\n",
    "        attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    )\n",
    "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    return sum_embeddings / sum_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9423e5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = sentences_test5\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sberbank-ai/sbert_large_mt_nlu_ru\")\n",
    "model = AutoModel.from_pretrained(\"sberbank-ai/sbert_large_mt_nlu_ru\")\n",
    "encoded_input = tokenizer(sentences, padding=True, truncation=True, max_length=24, return_tensors='pt')\n",
    "with torch.no_grad():\n",
    "    model_output = model(**encoded_input)\n",
    "sentence_embeddings5 = mean_pooling(model_output, encoded_input['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91d18bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(sentence_embeddings5, 'embeddings1.pt')\n",
    "torch.save(sentence_embeddings5, 'embeddings2.pt')\n",
    "torch.save(sentence_embeddings5, 'embeddings3.pt')\n",
    "torch.save(sentence_embeddings5, 'embeddings4.pt')\n",
    "torch.save(sentence_embeddings5, 'embeddings5.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090fbb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings1 = torch.load(\"embeddings1.pt\")\n",
    "embeddings2 = torch.load(\"embeddings2.pt\")\n",
    "embeddings3 = torch.load(\"embeddings3.pt\")\n",
    "embeddings4 = torch.load(\"embeddings4.pt\")\n",
    "embeddings5 = torch.load(\"embeddings5.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f511f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_concated = torch.cat(\n",
    "    [embeddings1, embeddings2, embeddings3, embeddings4, embeddings5]\n",
    ")\n",
    "embeddings_concated = torch.load(\"embeddings_concated.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9307dbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_clusters(message_embeddings, min_cluster_size, random_state=42):\n",
    "\n",
    "    umap_embeddings = umap.UMAP(random_state=42).fit_transform(message_embeddings)\n",
    "\n",
    "    clusters = hdbscan.HDBSCAN(\n",
    "        min_cluster_size=min_cluster_size,\n",
    "        metric=\"euclidean\",\n",
    "        cluster_selection_method=\"eom\",\n",
    "    ).fit(umap_embeddings)\n",
    "\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a2c2c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clusters_test = generate_clusters(\n",
    "    message_embeddings=embeddings_concated, min_cluster_size=5, random_state=42\n",
    ")\n",
    "clusters_test.labels_\n",
    "data = pd.read_csv(\"data_with_sentiment.csv\")\n",
    "data[\"cluster_id_test\"] = clusters_test.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb8b19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_of_test_cluster = pd.DataFrame(data.cluster_id_test.value_counts().head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43687da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_embeddings = umap.UMAP(random_state=42).fit_transform(embeddings_concated)\n",
    "hdb = hdbscan.HDBSCAN(gen_min_span_tree=True).fit(umap_embeddings)\n",
    "\n",
    "param_dist = {\n",
    "    \"min_cluster_size\": [2, 5, 7, 12, 15, 20, 25, 50, 100],\n",
    "    \"cluster_selection_method\": [\"eom\", \"leaf\"],\n",
    "    \"metric\": [\"euclidean\", \"manhattan\"],\n",
    "}\n",
    "\n",
    "# validity_scroer = \"hdbscan__hdbscan___HDBSCAN__validity_index\"\n",
    "validity_scorer = make_scorer(hdbscan.validity.validity_index, greater_is_better=True)\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(hdb, param_grid=param_dist, scoring=validity_scorer)\n",
    "\n",
    "grid_search.fit(umap_embeddings)\n",
    "\n",
    "\n",
    "print(f\"Best Parameters {grid_search.best_params_}\")\n",
    "print(f\"DBCV score :{grid_search.best_estimator_.relative_validity_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e211511",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = generate_clusters(\n",
    "    message_embeddings=embeddings_concated, min_cluster_size=2, random_state=42\n",
    ")\n",
    "clusters.labels_\n",
    "data[\"cluster_id\"] = clusters.labels_\n",
    "data.to_csv(\"data_with_clusters.csv\", index=False)\n",
    "result_of_cluster = pd.DataFrame(data.cluster_id.value_counts().head(10))\n",
    "result_of_cluster.to_excel(\"output10.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c965d292",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_with_clusters = pd.read_csv(\"data_with_clusters.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d52ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_clusters_interpretation = data_with_clusters[\n",
    "    [\"text_for_sentiment\", \"cluster_id\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f27a4fd",
   "metadata": {},
   "source": [
    "## To identify how the factor is related to opinions about kicksharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2aeee9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_clusters_sentiment = data_with_clusters[\n",
    "    data_with_clusters.cluster_id.isin(\n",
    "        [820, 528, 901, 902, 1244, 1380, 939, 1207, 1017, 954, 945, 765, 687]\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a722ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_cluster = {\n",
    "    820: \"\",\n",
    "    528: \"\",\n",
    "    901: \"\",\n",
    "    902: \"\",\n",
    "    1244: \"\",\n",
    "    1380: \"\",\n",
    "    939: \"\",\n",
    "    1207: \"\",\n",
    "    1017: \"\",\n",
    "    954: \"\",\n",
    "    945: \"\",\n",
    "    765: \"\",\n",
    "    687: \"  \",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a8fb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_clusters_sentiment1 = data_with_clusters_sentiment[\n",
    "    [\"text_for_sentiment\", \"cluster_id\", \"sentiment_analysis_value\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1325c4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_clusters_sentiment1[\"cluster_name\"] = data_with_clusters_sentiment1[\n",
    "    \"cluster_id\"\n",
    "].apply(lambda x: dict_cluster[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d30ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_clusters_sentiment1.cluster_name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473cf81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "crosstab3 = pd.crosstab(\n",
    "    data_with_clusters_sentiment1[\"cluster_name\"],\n",
    "    data_with_clusters_sentiment1[\"sentiment_analysis_value\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6025f72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.chi2_contingency(crosstab3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7465c09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def residuals(observed, expected):\n",
    "    return (observed - expected) / np.sqrt(expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a1ed4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected = np.array(\n",
    "    [\n",
    "        [24.14840989, 22.16607774, 4.68551237],\n",
    "        [17.99293286, 16.51590106, 3.49116608],\n",
    "        [9.9434629, 9.12720848, 1.92932862],\n",
    "        [33.14487633, 30.42402827, 6.43109541],\n",
    "        [7.1024735, 6.51943463, 1.37809187],\n",
    "        [23.67491166, 21.73144876, 4.59363958],\n",
    "        [17.99293286, 16.51590106, 3.49116608],\n",
    "    ]\n",
    ")\n",
    "F = np.array(crosstab3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b4c342",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = residuals(F, expected)\n",
    "resids = pd.DataFrame(a)\n",
    "resids.to_excel(\"resids.xlsx\")\n",
    "expected1 = pd.DataFrame(expected)\n",
    "expected1.to_excel(\"expected.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
